{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq_QnA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMiKvphar47U",
        "outputId": "eb2389c1-627e-42e0-f6e0-71be9edc5fd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDMRjWdOsFOq",
        "outputId": "16595001-b47f-44be-f983-476e6c175919"
      },
      "source": [
        "!wget https://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-23 06:16:32--  https://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8254496 (7.9M) [application/x-gzip]\n",
            "Saving to: ‘Question_Answer_Dataset_v1.2.tar.gz’\n",
            "\n",
            "Question_Answer_Dat 100%[===================>]   7.87M  1.30MB/s    in 5.8s    \n",
            "\n",
            "2021-06-23 06:16:38 (1.35 MB/s) - ‘Question_Answer_Dataset_v1.2.tar.gz’ saved [8254496/8254496]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71n52IaPsiTF"
      },
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "\n",
        "fname = 'Question_Answer_Dataset_v1.2.tar.gz'\n",
        "tar = tarfile.open(fname, \"r:gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMnwevVdumtf",
        "outputId": "5b5d7f5b-d49a-4503-a688-bf9b5c78eb9c"
      },
      "source": [
        "df1 = pd.read_csv('./Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt', sep='\\t', encoding='ISO-8859-1')\n",
        "df2 = pd.read_csv('./Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt', sep='\\t', encoding='ISO-8859-1')\n",
        "df3 = pd.read_csv('./Question_Answer_Dataset_v1.2/S08/question_answer_pairs.txt', sep='\\t', encoding='ISO-8859-1')\n",
        "\n",
        "dataset = pd.concat([df1,df2,df3], ignore_index=True, sort=False)\n",
        "print('Dataset - 1', df1.shape)\n",
        "print('Dataset - 2', df2.shape)\n",
        "print('Dataset - 3', df3.shape)\n",
        "print('Final dataset', dataset.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset - 1 (1715, 6)\n",
            "Dataset - 2 (1715, 6)\n",
            "Dataset - 3 (1715, 6)\n",
            "Final dataset (5145, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_aBcNuTOvTGi",
        "outputId": "c8cc9057-3067-4540-8334-af719852526c"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abraham_Lincoln</td>\n",
              "      <td>Did his mother die of pneumonia?</td>\n",
              "      <td>no</td>\n",
              "      <td>easy</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5140</th>\n",
              "      <td>Woodrow_Wilson</td>\n",
              "      <td>Was Wilson president of the American Political...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5141</th>\n",
              "      <td>Woodrow_Wilson</td>\n",
              "      <td>Did he not cast his ballot for John M. Palmer ...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>Woodrow_Wilson</td>\n",
              "      <td>Did Wilson not spend 1914 through the beginnin...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>Woodrow_Wilson</td>\n",
              "      <td>Was Wilson , a staunch opponent of antisemitis...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set3/a8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>Woodrow_Wilson</td>\n",
              "      <td>What happened in 1917?</td>\n",
              "      <td>raised billions through Liberty loans, imposed...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>medium</td>\n",
              "      <td>data/set3/a8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5145 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ArticleTitle  ...   ArticleFile\n",
              "0     Abraham_Lincoln  ...  data/set3/a4\n",
              "1     Abraham_Lincoln  ...  data/set3/a4\n",
              "2     Abraham_Lincoln  ...  data/set3/a4\n",
              "3     Abraham_Lincoln  ...  data/set3/a4\n",
              "4     Abraham_Lincoln  ...  data/set3/a4\n",
              "...               ...  ...           ...\n",
              "5140   Woodrow_Wilson  ...  data/set3/a8\n",
              "5141   Woodrow_Wilson  ...  data/set3/a8\n",
              "5142   Woodrow_Wilson  ...  data/set3/a8\n",
              "5143   Woodrow_Wilson  ...  data/set3/a8\n",
              "5144   Woodrow_Wilson  ...  data/set3/a8\n",
              "\n",
              "[5145 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkt2ECIRerrM",
        "outputId": "453a6674-0eb1-4284-f457-12d4b3edb5c0"
      },
      "source": [
        "print(dataset.Question.value_counts())\n",
        "print(dataset.Answer.value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Was King Victor Emmanuel III there to pay homage to Avogadro ?                                  18\n",
            "Where is Uruguay's oldest church?                                                               12\n",
            "Who founded Montevideo?                                                                         12\n",
            "Do all ducks \"quack\"?                                                                           12\n",
            "What is the largest living species of penguin?                                                  12\n",
            "                                                                                                ..\n",
            "Sibiu, a large city in Transylvania, was chosen as European Capital of Culture in what year?     3\n",
            "Was Fillmore one of the founders of the University of Buffalo?                                   3\n",
            "Volta became professor of physics in the Como high school in what year?                          3\n",
            "Is aquatic respiration in Australian freshwater turtles being studied?                           3\n",
            "Who was defeated for re-election in the`` Revolution of 1800'' by Thomas Jefferson?              3\n",
            "Name: Question, Length: 1032, dtype: int64\n",
            "Yes                                                                                                                      657\n",
            "yes                                                                                                                      633\n",
            "no                                                                                                                       174\n",
            "No                                                                                                                       171\n",
            "Yes.                                                                                                                     156\n",
            "                                                                                                                        ... \n",
            "at the Battle of Trenton, in his left shoulder                                                                             3\n",
            "By the length of the tail, panthers having longer tails than leopards                                                      3\n",
            "1890                                                                                                                       3\n",
            "Democratic Republicans                                                                                                     3\n",
            "They sometimes have problems with various skin diseases with dermatitis caused sometimes by mites or other parasites.      3\n",
            "Name: Answer, Length: 763, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nabd_D0nfm-B",
        "outputId": "1b66274b-2cef-46d3-9a26-c129d640c70b"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5145 entries, 0 to 5144\n",
            "Data columns (total 6 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   ArticleTitle              5145 non-null   object\n",
            " 1   Question                  5088 non-null   object\n",
            " 2   Answer                    4425 non-null   object\n",
            " 3   DifficultyFromQuestioner  3672 non-null   object\n",
            " 4   DifficultyFromAnswerer    4419 non-null   object\n",
            " 5   ArticleFile               5139 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 241.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiHPs9lepjuZ"
      },
      "source": [
        "dataset.dropna(subset=['Question', 'Answer'], inplace=True)\n",
        "dataset.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZmxsNM6f3_n",
        "outputId": "ec874e90-aa41-4c6c-b59b-9b41dfe708dc"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4425 entries, 0 to 4424\n",
            "Data columns (total 6 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   ArticleTitle              4425 non-null   object\n",
            " 1   Question                  4425 non-null   object\n",
            " 2   Answer                    4425 non-null   object\n",
            " 3   DifficultyFromQuestioner  3453 non-null   object\n",
            " 4   DifficultyFromAnswerer    4416 non-null   object\n",
            " 5   ArticleFile               4419 non-null   object\n",
            "dtypes: object(6)\n",
            "memory usage: 207.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ3FEQNpXEuK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXDQOMnkXOy9"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "#!pip install spacy --upgrade"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jAJX8ZMXRxc"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cef4y0QBXUjv"
      },
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ELlgwNXV4k"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en,\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            include_lengths=True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            include_lengths=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ad-YxV2XXGr"
      },
      "source": [
        "fields = [('Question', SRC), ('Answer', TRG)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2RMtdrCg5AB"
      },
      "source": [
        "example = [Example.fromlist([str(dataset.Question[i]), str(dataset.Answer[i])], fields) for i in range(dataset.shape[0])]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUxNGdZ5hHom"
      },
      "source": [
        "quesAnswer = Dataset(example, fields)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id5TJqiphO8Z"
      },
      "source": [
        "(train, test) = quesAnswer.split(split_ratio=[0.70, 0.30], random_state=random.seed(SEED))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87dWxjNyhR54",
        "outputId": "69d548a4-06a4-4db0-ec64-1c3b1621f9e2"
      },
      "source": [
        "print(f\"Number of training examples: {len(train.examples)}\")\n",
        "print(f\"Number of validation examples: {len(test.examples)}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 3098\n",
            "Number of validation examples: 1327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwjt3pRFhTVA",
        "outputId": "1b291cd2-94cc-4e35-f5ff-94596ac4e934"
      },
      "source": [
        "print(vars(train.examples[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Question': ['in', 'which', 'years', 'were', 'john', 'monroe', 'elected', 'as', 'president', '?'], 'Answer': ['1817', '-', '1825']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyzn4pUThXSr"
      },
      "source": [
        "SRC.build_vocab(train, min_freq = 2)\n",
        "TRG.build_vocab(train, min_freq = 2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5vLjKvzhkht",
        "outputId": "992deacb-a730-40db-c545-a4feffbdbb71"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (de) vocabulary: 2110\n",
            "Unique tokens in target (en) vocabulary: 1511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix4wLChJhltR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJwqppoghocS"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train, test), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    sort_key = lambda x: len(x.Question),\n",
        "    sort_within_batch=True, \n",
        "    device = device)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GhKOLDNhp1P"
      },
      "source": [
        "import os, pickle\n",
        "with open(F\"./gdrive/MyDrive/2021/tokenizer.pkl\", 'wb') as tokens:\n",
        "  pickle.dump( SRC.vocab.stoi, tokens)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcFOObvYhzER"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)        \n",
        "\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZti4eq8ngdG"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch  size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxvSyPzhniQH"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4SMhWZQnjwS"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVWFd8Asnl1E",
        "outputId": "f13f4c86-99da-4aec-d58c-1f882b260980"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(2110, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(1511, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=1511, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp01Xzqonnga",
        "outputId": "da536811-011b-4ed6-dbb0-153a7ecaee26"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,058,535 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9i4YMFBnp1x"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQWPwbG2nrgJ"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNt3Qj3knsjk"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, slen = batch.Question\n",
        "        trg, tlen = batch.Answer\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gOa-IwhntyS"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, slen = batch.Question\n",
        "            trg, tlen = batch.Answer\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUaKB_APn606"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbt8GF8Bn9JA",
        "outputId": "ff218e20-6025-4f05-e34c-083fa213f843"
      },
      "source": [
        "N_EPOCHS = 45\n",
        "CLIP = 1\n",
        "\n",
        "trainLoss = []\n",
        "testLoss = []\n",
        "\n",
        "best_test_loss = float('inf')\n",
        "model_save_name = 'questionAnswer.pt'\n",
        "path = F\"./gdrive/MyDrive/2021/{model_save_name}\" \n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), path) \n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Test Loss: {test_loss:.3f} |   Test PPL: {math.exp(test_loss):7.3f}')\n",
        "\n",
        "    trainLoss.append(train_loss)\n",
        "    testLoss.append(test_loss)\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 4s\n",
            "\tTrain Loss: 5.276 | Train PPL: 195.494\n",
            "\t Test Loss: 4.759 |   Test PPL: 116.601\n",
            "Epoch: 02 | Time: 0m 3s\n",
            "\tTrain Loss: 4.646 | Train PPL: 104.166\n",
            "\t Test Loss: 4.530 |   Test PPL:  92.723\n",
            "Epoch: 03 | Time: 0m 3s\n",
            "\tTrain Loss: 4.430 | Train PPL:  83.937\n",
            "\t Test Loss: 4.375 |   Test PPL:  79.449\n",
            "Epoch: 04 | Time: 0m 3s\n",
            "\tTrain Loss: 4.250 | Train PPL:  70.120\n",
            "\t Test Loss: 4.290 |   Test PPL:  72.957\n",
            "Epoch: 05 | Time: 0m 4s\n",
            "\tTrain Loss: 4.135 | Train PPL:  62.467\n",
            "\t Test Loss: 4.244 |   Test PPL:  69.699\n",
            "Epoch: 06 | Time: 0m 3s\n",
            "\tTrain Loss: 4.005 | Train PPL:  54.897\n",
            "\t Test Loss: 4.191 |   Test PPL:  66.067\n",
            "Epoch: 07 | Time: 0m 3s\n",
            "\tTrain Loss: 3.881 | Train PPL:  48.481\n",
            "\t Test Loss: 4.092 |   Test PPL:  59.861\n",
            "Epoch: 08 | Time: 0m 3s\n",
            "\tTrain Loss: 3.726 | Train PPL:  41.526\n",
            "\t Test Loss: 4.016 |   Test PPL:  55.484\n",
            "Epoch: 09 | Time: 0m 3s\n",
            "\tTrain Loss: 3.583 | Train PPL:  35.968\n",
            "\t Test Loss: 3.951 |   Test PPL:  51.994\n",
            "Epoch: 10 | Time: 0m 3s\n",
            "\tTrain Loss: 3.445 | Train PPL:  31.345\n",
            "\t Test Loss: 3.863 |   Test PPL:  47.626\n",
            "Epoch: 11 | Time: 0m 3s\n",
            "\tTrain Loss: 3.299 | Train PPL:  27.087\n",
            "\t Test Loss: 3.847 |   Test PPL:  46.835\n",
            "Epoch: 12 | Time: 0m 3s\n",
            "\tTrain Loss: 3.132 | Train PPL:  22.920\n",
            "\t Test Loss: 3.787 |   Test PPL:  44.142\n",
            "Epoch: 13 | Time: 0m 3s\n",
            "\tTrain Loss: 3.001 | Train PPL:  20.112\n",
            "\t Test Loss: 3.680 |   Test PPL:  39.637\n",
            "Epoch: 14 | Time: 0m 3s\n",
            "\tTrain Loss: 2.821 | Train PPL:  16.795\n",
            "\t Test Loss: 3.671 |   Test PPL:  39.293\n",
            "Epoch: 15 | Time: 0m 3s\n",
            "\tTrain Loss: 2.645 | Train PPL:  14.077\n",
            "\t Test Loss: 3.508 |   Test PPL:  33.383\n",
            "Epoch: 16 | Time: 0m 3s\n",
            "\tTrain Loss: 2.462 | Train PPL:  11.723\n",
            "\t Test Loss: 3.430 |   Test PPL:  30.889\n",
            "Epoch: 17 | Time: 0m 3s\n",
            "\tTrain Loss: 2.201 | Train PPL:   9.034\n",
            "\t Test Loss: 3.457 |   Test PPL:  31.736\n",
            "Epoch: 18 | Time: 0m 3s\n",
            "\tTrain Loss: 2.088 | Train PPL:   8.073\n",
            "\t Test Loss: 3.409 |   Test PPL:  30.225\n",
            "Epoch: 19 | Time: 0m 3s\n",
            "\tTrain Loss: 1.910 | Train PPL:   6.753\n",
            "\t Test Loss: 3.228 |   Test PPL:  25.232\n",
            "Epoch: 20 | Time: 0m 3s\n",
            "\tTrain Loss: 1.698 | Train PPL:   5.463\n",
            "\t Test Loss: 3.145 |   Test PPL:  23.212\n",
            "Epoch: 21 | Time: 0m 3s\n",
            "\tTrain Loss: 1.477 | Train PPL:   4.379\n",
            "\t Test Loss: 3.022 |   Test PPL:  20.527\n",
            "Epoch: 22 | Time: 0m 3s\n",
            "\tTrain Loss: 1.293 | Train PPL:   3.643\n",
            "\t Test Loss: 2.807 |   Test PPL:  16.565\n",
            "Epoch: 23 | Time: 0m 3s\n",
            "\tTrain Loss: 1.152 | Train PPL:   3.163\n",
            "\t Test Loss: 2.681 |   Test PPL:  14.593\n",
            "Epoch: 24 | Time: 0m 3s\n",
            "\tTrain Loss: 0.985 | Train PPL:   2.678\n",
            "\t Test Loss: 2.506 |   Test PPL:  12.258\n",
            "Epoch: 25 | Time: 0m 3s\n",
            "\tTrain Loss: 0.855 | Train PPL:   2.351\n",
            "\t Test Loss: 2.234 |   Test PPL:   9.333\n",
            "Epoch: 26 | Time: 0m 3s\n",
            "\tTrain Loss: 0.703 | Train PPL:   2.020\n",
            "\t Test Loss: 2.250 |   Test PPL:   9.487\n",
            "Epoch: 27 | Time: 0m 3s\n",
            "\tTrain Loss: 0.662 | Train PPL:   1.938\n",
            "\t Test Loss: 2.044 |   Test PPL:   7.724\n",
            "Epoch: 28 | Time: 0m 3s\n",
            "\tTrain Loss: 0.606 | Train PPL:   1.834\n",
            "\t Test Loss: 2.119 |   Test PPL:   8.325\n",
            "Epoch: 29 | Time: 0m 3s\n",
            "\tTrain Loss: 0.491 | Train PPL:   1.634\n",
            "\t Test Loss: 2.146 |   Test PPL:   8.547\n",
            "Epoch: 30 | Time: 0m 3s\n",
            "\tTrain Loss: 0.499 | Train PPL:   1.647\n",
            "\t Test Loss: 1.847 |   Test PPL:   6.340\n",
            "Epoch: 31 | Time: 0m 3s\n",
            "\tTrain Loss: 0.468 | Train PPL:   1.596\n",
            "\t Test Loss: 1.874 |   Test PPL:   6.512\n",
            "Epoch: 32 | Time: 0m 3s\n",
            "\tTrain Loss: 0.410 | Train PPL:   1.507\n",
            "\t Test Loss: 1.907 |   Test PPL:   6.733\n",
            "Epoch: 33 | Time: 0m 3s\n",
            "\tTrain Loss: 0.393 | Train PPL:   1.481\n",
            "\t Test Loss: 1.604 |   Test PPL:   4.971\n",
            "Epoch: 34 | Time: 0m 3s\n",
            "\tTrain Loss: 0.362 | Train PPL:   1.437\n",
            "\t Test Loss: 1.687 |   Test PPL:   5.403\n",
            "Epoch: 35 | Time: 0m 3s\n",
            "\tTrain Loss: 0.356 | Train PPL:   1.428\n",
            "\t Test Loss: 1.735 |   Test PPL:   5.670\n",
            "Epoch: 36 | Time: 0m 3s\n",
            "\tTrain Loss: 0.346 | Train PPL:   1.413\n",
            "\t Test Loss: 1.509 |   Test PPL:   4.522\n",
            "Epoch: 37 | Time: 0m 3s\n",
            "\tTrain Loss: 0.302 | Train PPL:   1.353\n",
            "\t Test Loss: 1.559 |   Test PPL:   4.755\n",
            "Epoch: 38 | Time: 0m 3s\n",
            "\tTrain Loss: 0.264 | Train PPL:   1.303\n",
            "\t Test Loss: 1.553 |   Test PPL:   4.727\n",
            "Epoch: 39 | Time: 0m 3s\n",
            "\tTrain Loss: 0.271 | Train PPL:   1.311\n",
            "\t Test Loss: 1.586 |   Test PPL:   4.883\n",
            "Epoch: 40 | Time: 0m 3s\n",
            "\tTrain Loss: 0.289 | Train PPL:   1.334\n",
            "\t Test Loss: 1.392 |   Test PPL:   4.021\n",
            "Epoch: 41 | Time: 0m 3s\n",
            "\tTrain Loss: 0.302 | Train PPL:   1.352\n",
            "\t Test Loss: 1.462 |   Test PPL:   4.315\n",
            "Epoch: 42 | Time: 0m 3s\n",
            "\tTrain Loss: 0.286 | Train PPL:   1.332\n",
            "\t Test Loss: 1.437 |   Test PPL:   4.208\n",
            "Epoch: 43 | Time: 0m 3s\n",
            "\tTrain Loss: 0.298 | Train PPL:   1.348\n",
            "\t Test Loss: 1.412 |   Test PPL:   4.105\n",
            "Epoch: 44 | Time: 0m 3s\n",
            "\tTrain Loss: 0.239 | Train PPL:   1.270\n",
            "\t Test Loss: 1.377 |   Test PPL:   3.963\n",
            "Epoch: 45 | Time: 0m 3s\n",
            "\tTrain Loss: 0.237 | Train PPL:   1.267\n",
            "\t Test Loss: 1.486 |   Test PPL:   4.420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUILsc8_rWLj",
        "outputId": "1ab33c7f-083f-4ced-a6e4-13345f1de432"
      },
      "source": [
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.377 | Test PPL:   3.963 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "GyH_OfuVoE54",
        "outputId": "db3f84b6-5cc1-42da-c07c-1847503c8ed1"
      },
      "source": [
        "# Plotting metrics to see how model as learned and loss decreased\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(N_EPOCHS), np.exp(trainLoss), marker='o')\n",
        "plt.plot(range(N_EPOCHS), np.exp(testLoss), marker = 'x')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
        "plt.title(\"Per-word perplexity Loss (e^loss)\")\n",
        "#plt.ylim([0,1.5])\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptN8gNIurcVr"
      },
      "source": [
        "import os, pickle\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8-I7K2_rd5x"
      },
      "source": [
        "def questionAnswer(ques, SRC, TRG, model, maxLength = 100):\n",
        "  model.eval()\n",
        "\n",
        "  # tokenize\n",
        "  tokenized = [tok.text.lower() for tok in nlp.tokenizer(ques)] \n",
        "  #print('tokenized: ', tokenized)\n",
        "\n",
        "  # add <sos> and add <eos>\n",
        "  tokenized = ['<sos>'] + tokenized + ['<eos>']\n",
        "  #print('tokenized: ', tokenized)\n",
        "\n",
        "  # convert to integer sequence using predefined tokenizer dictionary\n",
        "  indexed = [SRC.vocab.stoi[t] for t in tokenized]        \n",
        "  #print('indexed: ', indexed)\n",
        "\n",
        "  # compute no. of words        \n",
        "  length = [len(indexed)]\n",
        "  #print('length : ', length)\n",
        "\n",
        "  # convert to tensor                                    \n",
        "  tensor = torch.LongTensor(indexed).to(device)   \n",
        "  #print('tensor shape: ', tensor.shape)\n",
        "\n",
        "  # reshape in form of batch, no. of words           \n",
        "  tensor = tensor.unsqueeze(1) \n",
        "  #print('tensor shape: ', tensor.shape)\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    hidden, cell = model.encoder(tensor)\n",
        "\n",
        "  #first input to the decoder is the <sos> tokens\n",
        "  trg_indexes = [TRG.vocab.stoi[TRG.init_token]]\n",
        "\n",
        "  for t in range(1, maxLength):\n",
        "      \n",
        "      trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "      #insert input token embedding, previous hidden and previous cell states\n",
        "      #receive output tensor (predictions) and new hidden and cell states\n",
        "      with torch.no_grad():\n",
        "        output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "      \n",
        "      #place predictions in a tensor holding predictions for each token\n",
        "      #outputs[t] = output\n",
        "      \n",
        "      #decide if we are going to use teacher forcing or not\n",
        "      #teacher_force = random.random() < teacher_forcing_ratio\n",
        "      \n",
        "      #get the highest predicted token from our predictions\n",
        "      pred_token = output.argmax(1).item()\n",
        "      #print(pred_token)\n",
        "\n",
        "\n",
        "      trg_indexes.append(pred_token)\n",
        "\n",
        "      if pred_token == TRG.vocab.stoi[TRG.eos_token]:\n",
        "              break\n",
        "      \n",
        "  trg_tokens = [TRG.vocab.itos[i] for i in trg_indexes]\n",
        "  words = trg_tokens[1:(len(trg_tokens)-1)]\n",
        "\n",
        "  pred = ' '.join(words) \n",
        "\n",
        "  return pred"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4fm_VM3rm89",
        "outputId": "34e5f9fe-ca99-4a8a-ef84-10b40d3a96d6"
      },
      "source": [
        "for j in range(10):\n",
        "  i = random.randint(100,1000)\n",
        "  print('*'*50)\n",
        "  print('Input Quest    : ', dataset.Question[i])\n",
        "  pred = questionAnswer(dataset.Question[i], SRC, TRG, model)\n",
        "  print('Predicted Quest: ', pred)\n",
        "  print('Actual Quest 2 : ', dataset.Answer[i])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "Input Quest    :  Who also discovered that less than three percent of kangaroos exposed to the virus developed blindness ?\n",
            "Predicted Quest:  veterinarians\n",
            "Actual Quest 2 :  Veterinarians\n",
            "**************************************************\n",
            "Input Quest    :  Is Fillmore the first of two presidents to have been an indentured servant ?\n",
            "Predicted Quest:  yes\n",
            "Actual Quest 2 :  yes\n",
            "**************************************************\n",
            "Input Quest    :  When did Monroe's presidency expired?\n",
            "Predicted Quest:  march 4 , 1825 .\n",
            "Actual Quest 2 :  March 4, 1825\n",
            "**************************************************\n",
            "Input Quest    :  Does salmon remain the favorite of fly rod enthusiasts?\n",
            "Predicted Quest:  yes\n",
            "Actual Quest 2 :  Yes\n",
            "**************************************************\n",
            "Input Quest    :  Did ford get an award called \"Congressman's congressman\"?\n",
            "Predicted Quest:  yes\n",
            "Actual Quest 2 :  Yes\n",
            "**************************************************\n",
            "Input Quest    :  What is the primary item in an otter's diet?\n",
            "Predicted Quest:  fish\n",
            "Actual Quest 2 :  fish\n",
            "**************************************************\n",
            "Input Quest    :  Was James Cook the first to record the name \"Kangooroo?\"\n",
            "Predicted Quest:  yes\n",
            "Actual Quest 2 :  Yes\n",
            "**************************************************\n",
            "Input Quest    :  Did the Dutch build the Elmina Castle?\n",
            "Predicted Quest:  no\n",
            "Actual Quest 2 :  no\n",
            "**************************************************\n",
            "Input Quest    :  What positions Ford played in the school football team?\n",
            "Predicted Quest:  center and linebacker\n",
            "Actual Quest 2 :  Captain\n",
            "**************************************************\n",
            "Input Quest    :  What did James Monroe make in 1817?\n",
            "Predicted Quest:  two long tours\n",
            "Actual Quest 2 :  two long tours\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZPgTcFMm8I0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}