{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2SeqQuora_QuesPairs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hKFBxmtARLx",
        "outputId": "c2146c8a-125b-4ce0-d523-5ac40cabcf5b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JZbVE9uAaMv",
        "outputId": "44cbbecc-6e34-497d-def5-4dde153818f4"
      },
      "source": [
        "!ls ./gdrive/MyDrive/NLP/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PracticeData  question2question1.pt  question2question.pt  tokenizer.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bantyuaJp0Kk",
        "outputId": "7acda204-4b97-4cd0-d832-7ce1aef9c3d9"
      },
      "source": [
        "!wget http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-23 10:42:21--  http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\n",
            "Resolving qim.fs.quoracdn.net (qim.fs.quoracdn.net)... 151.101.1.2, 151.101.65.2, 151.101.129.2, ...\n",
            "Connecting to qim.fs.quoracdn.net (qim.fs.quoracdn.net)|151.101.1.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58176133 (55M) [text/tab-separated-values]\n",
            "Saving to: ‘quora_duplicate_questions.tsv’\n",
            "\n",
            "quora_duplicate_que 100%[===================>]  55.48M   178MB/s    in 0.3s    \n",
            "\n",
            "2021-06-23 10:42:23 (178 MB/s) - ‘quora_duplicate_questions.tsv’ saved [58176133/58176133]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85loFem9qZqv"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "AvC9KcWAquIv",
        "outputId": "f83f4519-4514-4732-b465-c2dd8313e4fb"
      },
      "source": [
        "df = pd.read_csv(\"quora_duplicate_questions.tsv\", sep='\\t')\n",
        "print(df.shape)\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404290, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404285</th>\n",
              "      <td>404285</td>\n",
              "      <td>433578</td>\n",
              "      <td>379845</td>\n",
              "      <td>How many keywords are there in the Racket prog...</td>\n",
              "      <td>How many keywords are there in PERL Programmin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404286</th>\n",
              "      <td>404286</td>\n",
              "      <td>18840</td>\n",
              "      <td>155606</td>\n",
              "      <td>Do you believe there is life after death?</td>\n",
              "      <td>Is it true that there is life after death?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404287</th>\n",
              "      <td>404287</td>\n",
              "      <td>537928</td>\n",
              "      <td>537929</td>\n",
              "      <td>What is one coin?</td>\n",
              "      <td>What's this coin?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404288</th>\n",
              "      <td>404288</td>\n",
              "      <td>537930</td>\n",
              "      <td>537931</td>\n",
              "      <td>What is the approx annual cost of living while...</td>\n",
              "      <td>I am having little hairfall problem but I want...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404289</th>\n",
              "      <td>404289</td>\n",
              "      <td>537932</td>\n",
              "      <td>537933</td>\n",
              "      <td>What is like to have sex with cousin?</td>\n",
              "      <td>What is it like to have sex with your cousin?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>404290 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...  is_duplicate\n",
              "0            0  ...             0\n",
              "1            1  ...             0\n",
              "2            2  ...             0\n",
              "3            3  ...             0\n",
              "4            4  ...             0\n",
              "...        ...  ...           ...\n",
              "404285  404285  ...             0\n",
              "404286  404286  ...             1\n",
              "404287  404287  ...             0\n",
              "404288  404288  ...             0\n",
              "404289  404289  ...             0\n",
              "\n",
              "[404290 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny9d7bZhq7FO"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.data import Field, BucketIterator, Example, Dataset\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBXk_I4ardVy"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "#!pip install spacy --upgrade"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjwCRxOrrgN_"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC-k6CB5vaci"
      },
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrmUrSGermrF"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en,\n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            include_lengths=True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True,\n",
        "            include_lengths=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ-habA5uWFz"
      },
      "source": [
        "fields = [('question1', SRC), ('question2', TRG)]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IiRIhESikVZ",
        "outputId": "53613308-c62b-4b32-c30c-467d69c44025"
      },
      "source": [
        "df.is_duplicate.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    255027\n",
              "1    149263\n",
              "Name: is_duplicate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWM-P1NY2PNd"
      },
      "source": [
        "# Taking sample fo dataset\n",
        "#df1 = df.iloc[:5000,:]\n",
        "#print(df1.shape)\n",
        "df = df[df['is_duplicate'] == 1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wNuIK8AqzT5",
        "outputId": "a821c63e-14e8-4386-e2e7-1d7856bb7358"
      },
      "source": [
        "print(df.question1.value_counts())\n",
        "print(df.question1.apply(len) > 1)\n",
        "print(df.shape[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How do I improve my English speaking?                                                         50\n",
            "How does the ban on 500 and 1000 rupee notes helps to identify black money and corruption?    48\n",
            "How can changing 500 and 1000 rupee notes end the black money in India?                       47\n",
            "How do I improve my English language?                                                         47\n",
            "What should I do to earn money online?                                                        46\n",
            "                                                                                              ..\n",
            "How can you be a werewolf in real life?                                                        1\n",
            "Where can I find an efficient rubbish removal service?                                         1\n",
            "Why does Israel engage in aparthied?                                                           1\n",
            "Which is your favourite question and favourite answer on Quora?                                1\n",
            "What does 'dragon blood' do in \"Harry Potter\"?                                                 1\n",
            "Name: question1, Length: 86169, dtype: int64\n",
            "5         True\n",
            "7         True\n",
            "11        True\n",
            "12        True\n",
            "13        True\n",
            "          ... \n",
            "404280    True\n",
            "404281    True\n",
            "404282    True\n",
            "404284    True\n",
            "404286    True\n",
            "Name: question1, Length: 149263, dtype: bool\n",
            "149263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qU9NqBik8Ou"
      },
      "source": [
        "df.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z1fYqHbtkcCt",
        "outputId": "01080daa-19dd-4bdb-e805-1eb0100fe204"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>How do I read and find my YouTube comments?</td>\n",
              "      <td>How can I see all my Youtube comments?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>What can make Physics easy to learn?</td>\n",
              "      <td>How can you make physics easy to learn?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>What was your first sexual experience like?</td>\n",
              "      <td>What was your first sexual experience?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   5    11  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n",
              "1   7    15  ...          What should I do to be a great geologist?            1\n",
              "2  11    23  ...             How can I see all my Youtube comments?            1\n",
              "3  12    25  ...            How can you make physics easy to learn?            1\n",
              "4  13    27  ...             What was your first sexual experience?            1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsP0jztAnAQH",
        "outputId": "dd72aa62-d3e3-4d84-d657-1d110883c291"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 149263 entries, 0 to 149262\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   id            149263 non-null  int64 \n",
            " 1   qid1          149263 non-null  int64 \n",
            " 2   qid2          149263 non-null  int64 \n",
            " 3   question1     149263 non-null  object\n",
            " 4   question2     149263 non-null  object\n",
            " 5   is_duplicate  149263 non-null  int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 6.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8w4JTYxulCS"
      },
      "source": [
        "example = [Example.fromlist([str(df.question1[i]), str(df.question2[i])], fields) for i in range(df.shape[0])]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDzIDiE4vKKP"
      },
      "source": [
        "quoraDataset = Dataset(example, fields)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caDXg78kxwnM"
      },
      "source": [
        "(train, test) = quoraDataset.split(split_ratio=[0.70, 0.30], random_state=random.seed(SEED))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-p_KLQDx3rO",
        "outputId": "74aea144-b301-4b10-b990-2a8132b329a9"
      },
      "source": [
        "print(f\"Number of training examples: {len(train.examples)}\")\n",
        "print(f\"Number of validation examples: {len(test.examples)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 104484\n",
            "Number of validation examples: 44779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ladEex6I5ore",
        "outputId": "61db1026-6ce8-4064-dce7-e7540ce722c9"
      },
      "source": [
        "print(vars(train.examples[0]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'question1': ['what', 'are', 'the', 'most', 'intellectually', 'stimulating', 'movies', 'you', 'have', 'ever', 'seen', '?'], 'question2': ['what', 'are', 'the', 'most', 'intellectually', 'stimulating', 'films', 'you', 'have', 'ever', 'watched', '?']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "airwTeVf5tWe"
      },
      "source": [
        "SRC.build_vocab(train, min_freq = 2)\n",
        "TRG.build_vocab(train, min_freq = 2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_xEho0uyB3b",
        "outputId": "9442d96a-b6bb-4778-f579-d95c7e3d7367"
      },
      "source": [
        "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in source (de) vocabulary: 14522\n",
            "Unique tokens in target (en) vocabulary: 14469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXjm3RyFyQJk"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD9_xk_dyQ4Y"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train, test), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    sort_key = lambda x: len(x.question1),\n",
        "    sort_within_batch=True, \n",
        "    device = device)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKfNIDewOd6F"
      },
      "source": [
        "#SRC.vocab.stoi"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQlExBiUOZ72"
      },
      "source": [
        "import os, pickle\n",
        "with open(F\"./gdrive/MyDrive/NLP/tokenizer.pkl\", 'wb') as tokens:\n",
        "  pickle.dump( SRC.vocab.stoi, tokens)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqeKSNVjV51E"
      },
      "source": [
        "# Final Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SsiGjE5yca-"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)        \n",
        "\n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krusrjV_8y0F"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch  size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72FCbncU86eL"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr2yXqIc88VY"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzgi4Ic8-6K",
        "outputId": "6b3d4d2a-42ee-4e76-f545-cb1124f4e8ce"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(14522, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(14469, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=512, out_features=14469, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgGfDjLo9A_W",
        "outputId": "876e44eb-b0d3-4379-8dac-d51cdd7a579a"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 22,200,709 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk7taZQc9EsQ"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCj1_zCI9F87"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrBu_mGE9G74"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, slen = batch.question1\n",
        "        trg, tlen = batch.question2\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBwuinnH9OYW"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, slen = batch.question1\n",
        "            trg, tlen = batch.question2\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8aMTZVB9Qji"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta9VB5319S2o",
        "outputId": "4a192f8b-9662-4243-fe8e-63452c17b021"
      },
      "source": [
        "N_EPOCHS = 22\n",
        "CLIP = 1\n",
        "\n",
        "trainLoss = []\n",
        "testLoss = []\n",
        "\n",
        "best_test_loss = float('inf')\n",
        "model_save_name = 'question2question1.pt'\n",
        "path = F\"./gdrive/MyDrive/NLP/{model_save_name}\" \n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    test_loss = evaluate(model, test_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        torch.save(model.state_dict(), path) \n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Test Loss: {test_loss:.3f} |   Test PPL: {math.exp(test_loss):7.3f}')\n",
        "\n",
        "    trainLoss.append(train_loss)\n",
        "    testLoss.append(test_loss)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 4m 36s\n",
            "\tTrain Loss: 5.004 | Train PPL: 148.934\n",
            "\t Test Loss: 4.777 |   Test PPL: 118.765\n",
            "Epoch: 02 | Time: 4m 35s\n",
            "\tTrain Loss: 4.235 | Train PPL:  69.060\n",
            "\t Test Loss: 4.378 |   Test PPL:  79.655\n",
            "Epoch: 03 | Time: 4m 36s\n",
            "\tTrain Loss: 3.834 | Train PPL:  46.235\n",
            "\t Test Loss: 4.164 |   Test PPL:  64.343\n",
            "Epoch: 04 | Time: 4m 36s\n",
            "\tTrain Loss: 3.554 | Train PPL:  34.939\n",
            "\t Test Loss: 4.018 |   Test PPL:  55.574\n",
            "Epoch: 05 | Time: 4m 37s\n",
            "\tTrain Loss: 3.355 | Train PPL:  28.652\n",
            "\t Test Loss: 3.907 |   Test PPL:  49.737\n",
            "Epoch: 06 | Time: 4m 36s\n",
            "\tTrain Loss: 3.190 | Train PPL:  24.281\n",
            "\t Test Loss: 3.837 |   Test PPL:  46.374\n",
            "Epoch: 07 | Time: 4m 33s\n",
            "\tTrain Loss: 3.061 | Train PPL:  21.358\n",
            "\t Test Loss: 3.767 |   Test PPL:  43.241\n",
            "Epoch: 08 | Time: 4m 35s\n",
            "\tTrain Loss: 2.934 | Train PPL:  18.808\n",
            "\t Test Loss: 3.703 |   Test PPL:  40.564\n",
            "Epoch: 09 | Time: 4m 33s\n",
            "\tTrain Loss: 2.832 | Train PPL:  16.984\n",
            "\t Test Loss: 3.651 |   Test PPL:  38.511\n",
            "Epoch: 10 | Time: 4m 34s\n",
            "\tTrain Loss: 2.742 | Train PPL:  15.523\n",
            "\t Test Loss: 3.643 |   Test PPL:  38.196\n",
            "Epoch: 11 | Time: 4m 33s\n",
            "\tTrain Loss: 2.662 | Train PPL:  14.323\n",
            "\t Test Loss: 3.625 |   Test PPL:  37.517\n",
            "Epoch: 12 | Time: 4m 33s\n",
            "\tTrain Loss: 2.586 | Train PPL:  13.274\n",
            "\t Test Loss: 3.582 |   Test PPL:  35.952\n",
            "Epoch: 13 | Time: 4m 33s\n",
            "\tTrain Loss: 2.534 | Train PPL:  12.603\n",
            "\t Test Loss: 3.548 |   Test PPL:  34.736\n",
            "Epoch: 14 | Time: 4m 33s\n",
            "\tTrain Loss: 2.459 | Train PPL:  11.689\n",
            "\t Test Loss: 3.559 |   Test PPL:  35.144\n",
            "Epoch: 15 | Time: 4m 33s\n",
            "\tTrain Loss: 2.405 | Train PPL:  11.081\n",
            "\t Test Loss: 3.548 |   Test PPL:  34.745\n",
            "Epoch: 16 | Time: 4m 33s\n",
            "\tTrain Loss: 2.357 | Train PPL:  10.556\n",
            "\t Test Loss: 3.532 |   Test PPL:  34.195\n",
            "Epoch: 17 | Time: 4m 33s\n",
            "\tTrain Loss: 2.309 | Train PPL:  10.064\n",
            "\t Test Loss: 3.516 |   Test PPL:  33.642\n",
            "Epoch: 18 | Time: 4m 33s\n",
            "\tTrain Loss: 2.256 | Train PPL:   9.542\n",
            "\t Test Loss: 3.513 |   Test PPL:  33.558\n",
            "Epoch: 19 | Time: 4m 34s\n",
            "\tTrain Loss: 2.205 | Train PPL:   9.073\n",
            "\t Test Loss: 3.539 |   Test PPL:  34.438\n",
            "Epoch: 20 | Time: 4m 33s\n",
            "\tTrain Loss: 2.170 | Train PPL:   8.754\n",
            "\t Test Loss: 3.509 |   Test PPL:  33.404\n",
            "Epoch: 21 | Time: 4m 34s\n",
            "\tTrain Loss: 2.137 | Train PPL:   8.475\n",
            "\t Test Loss: 3.505 |   Test PPL:  33.269\n",
            "Epoch: 22 | Time: 4m 33s\n",
            "\tTrain Loss: 2.095 | Train PPL:   8.129\n",
            "\t Test Loss: 3.525 |   Test PPL:  33.955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFDGrhyH9ubE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec56e1a-157f-43a2-e671-6fe13c04bfcc"
      },
      "source": [
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.505 | Test PPL:  33.269 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "rhntVJeDO7R_",
        "outputId": "4bcae509-1381-4c89-b2b3-4ff077c8557e"
      },
      "source": [
        "# Plotting metrics to see how model as learned and loss decreased\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(N_EPOCHS), np.exp(trainLoss), marker='o')\n",
        "plt.plot(range(N_EPOCHS), np.exp(testLoss), marker = 'x')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
        "plt.title(\"Per-word perplexity Loss (e^loss)\")\n",
        "#plt.ylim([0,1.5])\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpDrh9PAnNeO"
      },
      "source": [
        "import os, pickle\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Af2_gqEciW"
      },
      "source": [
        "def rephraseQuestion(ques, SRC, TRG, model, maxLength = 100):\n",
        "  model.eval()\n",
        "\n",
        "  # tokenize\n",
        "  tokenized = [tok.text.lower() for tok in nlp.tokenizer(ques)] \n",
        "  #print('tokenized: ', tokenized)\n",
        "\n",
        "  # add <sos> and add <eos>\n",
        "  tokenized = ['<sos>'] + tokenized + ['<eos>']\n",
        "  #print('tokenized: ', tokenized)\n",
        "\n",
        "  # convert to integer sequence using predefined tokenizer dictionary\n",
        "  indexed = [SRC.vocab.stoi[t] for t in tokenized]        \n",
        "  #print('indexed: ', indexed)\n",
        "\n",
        "  # compute no. of words        \n",
        "  length = [len(indexed)]\n",
        "  #print('length : ', length)\n",
        "\n",
        "  # convert to tensor                                    \n",
        "  tensor = torch.LongTensor(indexed).to(device)   \n",
        "  #print('tensor shape: ', tensor.shape)\n",
        "\n",
        "  # reshape in form of batch, no. of words           \n",
        "  tensor = tensor.unsqueeze(1) \n",
        "  #print('tensor shape: ', tensor.shape)\n",
        "\n",
        "\n",
        "  with torch.no_grad():\n",
        "    hidden, cell = model.encoder(tensor)\n",
        "\n",
        "  #first input to the decoder is the <sos> tokens\n",
        "  trg_indexes = [TRG.vocab.stoi[TRG.init_token]]\n",
        "\n",
        "  for t in range(1, maxLength):\n",
        "      \n",
        "      trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "      #insert input token embedding, previous hidden and previous cell states\n",
        "      #receive output tensor (predictions) and new hidden and cell states\n",
        "      with torch.no_grad():\n",
        "        output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
        "      \n",
        "      #place predictions in a tensor holding predictions for each token\n",
        "      #outputs[t] = output\n",
        "      \n",
        "      #decide if we are going to use teacher forcing or not\n",
        "      #teacher_force = random.random() < teacher_forcing_ratio\n",
        "      \n",
        "      #get the highest predicted token from our predictions\n",
        "      pred_token = output.argmax(1).item()\n",
        "      #print(pred_token)\n",
        "\n",
        "\n",
        "      trg_indexes.append(pred_token)\n",
        "\n",
        "      if pred_token == TRG.vocab.stoi[TRG.eos_token]:\n",
        "              break\n",
        "      \n",
        "  trg_tokens = [TRG.vocab.itos[i] for i in trg_indexes]\n",
        "  words = trg_tokens[1:(len(trg_tokens)-1)]\n",
        "\n",
        "  pred = ' '.join(words) \n",
        "\n",
        "  return pred"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZJCdrTBRvEh",
        "outputId": "c3ec6e4a-449e-4e9c-ad85-41a508bb3d49"
      },
      "source": [
        "for j in range(10):\n",
        "  i = random.randint(100,10000)\n",
        "  print('*'*50)\n",
        "  print('Input Quest    : ', df.question1[i])\n",
        "  pred = rephraseQuestion(df.question1[i], SRC, TRG, model)\n",
        "  print('Predicted Quest: ', pred)\n",
        "  print('Actual Quest 2 : ', df.question2[i])\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "Input Quest    :  What is it like when the wife is older than the husband?\n",
            "Predicted Quest:  what is it like to be a elder elder elder ?\n",
            "Actual Quest 2 :  How does it feel for a wife to be elder than the husband?\n",
            "**************************************************\n",
            "Input Quest    :  Where can I get very friendly property transactions services in Sydney?\n",
            "Predicted Quest:  where can i get best support property transactions in sydney ?\n",
            "Actual Quest 2 :  Where can I get best property transaction support in Sydney?\n",
            "**************************************************\n",
            "Input Quest    :  What do you want from life?\n",
            "Predicted Quest:  what do you want to do in your life ?\n",
            "Actual Quest 2 :  What you want to do in your life?\n",
            "**************************************************\n",
            "Input Quest    :  What are some interesting facts about medicine?\n",
            "Predicted Quest:  what are some interesting facts about <unk> ?\n",
            "Actual Quest 2 :  What are some insane facts about medicine?\n",
            "**************************************************\n",
            "Input Quest    :  Why are some people so insecure?\n",
            "Predicted Quest:  why are people so insecure ?\n",
            "Actual Quest 2 :  Why are so many people insecure?\n",
            "**************************************************\n",
            "Input Quest    :  I wanna start preparing for ias exam, how should I proceed?\n",
            "Predicted Quest:  how do i start preparing for ias exam ?\n",
            "Actual Quest 2 :  How should I start preparing for UPSC(IAS) exams?\n",
            "**************************************************\n",
            "Input Quest    :  How do you improve your programming skills?\n",
            "Predicted Quest:  how can i improve my programming skills ?\n",
            "Actual Quest 2 :  Sir how to increase programming skills?\n",
            "**************************************************\n",
            "Input Quest    :  What are some mind-blowing mobile inventions that exist that most people don't know about?\n",
            "Predicted Quest:  what are some mind - blowing mobile tools that exist that most people do n't know about ?\n",
            "Actual Quest 2 :  What are some mind blowing phone tech Inventions that most people don't know about?\n",
            "**************************************************\n",
            "Input Quest    :  How can one invest ₹10,000, and in what way?\n",
            "Predicted Quest:  how can i invest the ?\n",
            "Actual Quest 2 :  How do I invest ₹10,000?\n",
            "**************************************************\n",
            "Input Quest    :  What conspiracy theories turned out to be true?\n",
            "Predicted Quest:  what is the most unlikely conspiracy theories that turned out to be true ?\n",
            "Actual Quest 2 :  What is a conspiracy theory that turned out to be real?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeAQCOEVpnMk"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}